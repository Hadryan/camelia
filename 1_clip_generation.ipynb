{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP: Video generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7638b462e72c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msunflower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msunflower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msong_analyzer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSongAnalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msunflower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msunflower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_wav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msunflower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msunflower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msong_visualizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualize_waveform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git repos/camelia/sunflower/sunflower/song_visualizer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_waveform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# General\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "# Audio\n",
    "\n",
    "from sunflower.sunflower.song_loader import Song, load_from_disk\n",
    "from sunflower.sunflower.song_analyzer import SongAnalyzer\n",
    "from sunflower.sunflower.utils import export_wav\n",
    "from sunflower.sunflower.song_visualizer import visualize_waveform\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Video\n",
    "\n",
    "from moviepy.editor import *\n",
    "from moviepy.audio.AudioClip import AudioArrayClip\n",
    "import moviepy\n",
    "import pygame\n",
    "\n",
    "# Autoreloading for easier development\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading example file\n",
    "\n",
    "raw_audio, extension = load_from_disk(\"assets/laylow_casting_slowed.mp3\")\n",
    "\n",
    "song = Song(raw_audio, extension)\n",
    "\n",
    "song.print_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing song\n",
    "\n",
    "song_analyzer = SongAnalyzer(song)\n",
    "song_analyzer.detect_tempo()\n",
    "\n",
    "print(song_analyzer.tempo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_size(clip): \n",
    "    \n",
    "    # Resize\n",
    "    clip=clip.crop(x_center=int(clip.w/2), \n",
    "                   y_center=int(clip.h/2),\n",
    "                   width=min(clip.w,clip.h), \n",
    "                   height=min(clip.w,clip.h))\n",
    "    \n",
    "    return(clip)\n",
    "\n",
    "def invert_green_blue(image):\n",
    "    return image[:,:,[0,1,1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioclip = AudioArrayClip(song.waveform , \n",
    "                           fps=song.sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "WIDTH = 600\n",
    "HEIGHT = 600\n",
    "\n",
    "screensize = (WIDTH,HEIGHT)\n",
    "prop_center = 0.8\n",
    "\n",
    "BPM = 112\n",
    "duration = 60/BPM\n",
    "\n",
    "artist_name = \"Laylow\"\n",
    "track_name = \"Casting\"\n",
    "\n",
    "# Fonts\n",
    "\n",
    "textwidth = 0.2*WIDTH\n",
    "textheight = 0.2*HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtClip_artist = TextClip(artist_name,color='white', font=\"Helvetica\",\n",
    "                   kerning = 5, size=(textwidth,None))\n",
    "\n",
    "txtClip_track = TextClip(track_name,color='LightPink', font=\"Helvetica-bold\",\n",
    "                   kerning = 5, size=(textwidth,None))\n",
    "\n",
    "# Load all the videos\n",
    "\n",
    "# Zankyou\n",
    "\n",
    "clip_og = VideoFileClip(\"assets/zankyou.mp4\")\n",
    "clip_og=squared_size(clip_og)\n",
    "clip_og=clip_og.resize([int(size*prop_center) for size in screensize])\n",
    "\n",
    "# VHS\n",
    "\n",
    "clip_vhs = VideoFileClip(\"assets/vhs.mp4\")\n",
    "clip_vhs=squared_size(clip_vhs)\n",
    "clip_vhs=clip_vhs.resize(screensize)\n",
    "\n",
    "masked_clip = clip_vhs.subclip(500,550).fx(moviepy.editor.vfx.mask_color, color=[0, 0, 0], thr=100, s=5)\n",
    "\n",
    "# Background\n",
    "\n",
    "clip_background = VideoFileClip(\"assets/vhs.mp4\")\n",
    "clip_background =squared_size(clip_background)\n",
    "clip_background=clip_background.resize(screensize)\n",
    "\n",
    "# Son\n",
    "\n",
    "clip = clip_vhs.subclip(120,120+4*duration)\n",
    "\n",
    "cuts = [51,53]\n",
    "\n",
    "\n",
    "clip=concatenate_videoclips([clip,clip_og.subclip(cuts[0],cuts[0]+duration).loop(duration=duration*28)])\n",
    "clip=concatenate_videoclips([clip,clip_og.subclip(cuts[1],cuts[1]+duration).loop(duration=duration*28)])\n",
    "    \n",
    "\n",
    "# Looping the clip\n",
    "clip = clip.loop(n=2)\n",
    "\n",
    "# Say that you want it to appear 10s at the center of the screen\n",
    "txtClip_artist = txtClip_artist.set_pos((WIDTH/2 - txtClip_artist.w/2,0.1*HEIGHT)).set_start(duration*2).set_duration(duration)\n",
    "\n",
    "# Say that you want it to appear 10s at the center of the screen\n",
    "txtClip_track = txtClip_track.set_pos((WIDTH/2 - txtClip_track.w/2,0.25*HEIGHT)).set_start(duration*2).set_duration(duration)\n",
    "\n",
    "\n",
    "# Overlay the text clip on the first video clip\n",
    "video = CompositeVideoClip([clip, txtClip_artist, txtClip_track,masked_clip])\n",
    "\n",
    "video=video.set_audio(audioclip)\n",
    "\n",
    "\n",
    "\n",
    "# Cut de la video \n",
    "\n",
    "video = video.subclip(0,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.preview(fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video.ipython_display(fps=20, autoplay=1,maxduration=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.write_videofile(\"test2.mp4\", temp_audiofile=\"temp-audio.m4a\", remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MovieEditorDec",
   "language": "python",
   "name": "movieeditordec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
